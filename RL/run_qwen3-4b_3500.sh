#!/bin/bash
# Tested successfully on the hiyouga/verl:ngc-th2.6.0-cu126-vllm0.8.4-flashinfer0.2.2-cxx11abi0 image.
# It outperforms the Qwen2 7B base model by two percentage points on the test set of GSM8K.

#set -x

#WANDB_PROJECT=verl_grpo_dna_assemble_3500
#python -m wandb login --relogin  b89c31f42e528d3c353f06f0f263ca3d8335ab57

#python3 -m verl.trainer.main_ppo \
#    custom_reward_function.path=/path/demo/script/RL/reward_function.py \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene1000_3500_5_11_train.parquet \
#    data.val_files=/path/demo/genegene1000_3500_5_11_val.parquet \
#    data.train_batch_size=16 \
#    data.max_prompt_length=22000 \
#    data.max_response_length=10000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/model_weights/Qwen/Qwen3-4B-Instruct-2507 \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=4 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_coef=0.001 \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.entropy_coeff=0 \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=False \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=False \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.8 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=2 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=160960 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.05 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='qwen3_4b-instruct_gene3500_11_rp' \
#    trainer.n_gpus_per_node=8 \
#    trainer.nnodes=1 \
#    trainer.save_freq=20 \
#    trainer.test_freq=5 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@


#python3 -m verl.trainer.main_ppo \
#    custom_reward_function.path=/path/demo/script/RL/reward_function.py \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_1k_2k_noise_train.parquet \
#    data.val_files=/path/demo/genegene_1k_2k_noise_val.parquet \
#    data.train_batch_size=4 \
#    data.max_prompt_length=29000 \
#    data.max_response_length=10000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/script/RL/checkpoints/verl_grpo_dna_assemble_3500/qwen3_4b-instruct_gene3500_11_rp/step_100_hg \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=4 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_coef=0.001 \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.entropy_coeff=0 \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=False \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=False \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.6 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=2 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=160960 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.05 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_100_hg_gene2000_10_rp' \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=20 \
#    trainer.test_freq=5 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@


#python3 -m verl.trainer.main_ppo \
#    custom_reward_function.path=/path/demo/script/RL/reward_function.py \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_1k_2k_noise_train.parquet \
#    data.val_files=/path/demo/genegene_1k_2k_noise_val.parquet \
#    data.train_batch_size=4 \
#    data.max_prompt_length=29000 \
#    data.max_response_length=10000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/model_weights/Qwen/Qwen3-1___7B \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=4 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_coef=0.001 \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.entropy_coeff=0 \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=False \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=False \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.6 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=2 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=160960 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.05 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='qwen3_1___7B_gene2000_10_rp' \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=20 \
#    trainer.test_freq=5 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@


#python3 -m verl.trainer.main_ppo \
#    custom_reward_function.path=/path/demo/script/RL/reward_function.py \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_drop_original_train.parquet \
#    data.val_files=/path/demo/genegene_drop_original_val.parquet \
#    data.train_batch_size=4 \
#    data.max_prompt_length=29000 \
#    data.max_response_length=10000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_100_hg_gene2000_10_rp/step_320_hg \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=4 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_coef=0.001 \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.entropy_coeff=0 \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=False \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=False \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.6 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=2 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=160960 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.05 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_320_hg_gene2000_drop_original_rp_test' \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=20 \
#    trainer.test_freq=5 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@


#python3 -m verl.trainer.main_ppo \
#    custom_reward_function.path=/path/demo/script/RL/reward_function_similarity.py \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_copypaste_train.parquet \
#    data.val_files=/path/demo/genegene_copypaste_val.parquet \
#    data.train_batch_size=4 \
#    data.max_prompt_length=40000 \
#    data.max_response_length=4000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_320_hg_gene2000_drop_original_rp/step_460_hg \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=4 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_coef=0.001 \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.entropy_coeff=0 \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=False \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=False \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.6 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=1 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=160960 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.05 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_460_hg_gene2000_copypaste_rp_v2' \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=20 \
#    trainer.test_freq=10 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@


#python3 -m verl.trainer.main_ppo \
#    custom_reward_function.path=/path/demo/script/RL/reward_function_similarity.py \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_copypaste_train.parquet \
#    data.val_files=/path/demo/genegene_copypaste_val.parquet \
#    data.train_batch_size=8 \
#    data.max_prompt_length=40000 \
#    data.max_response_length=4000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_320_hg_gene2000_drop_original_rp/step_460_hg \
#    actor_rollout_ref.actor.optim.lr=2e-6 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_coef=0.05 \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.entropy_coeff=0.01 \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=True \
#    +actor_rollout_ref.ref.gpu_offload=True \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=4 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_460_hg_grpo_safe_lr_sched_v1' \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=20 \
#    trainer.test_freq=10 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@


#python3 -m verl.trainer.main_ppo \
#    custom_reward_function.path=/path/demo/script/RL/reward_function_similarity.py \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_copypaste_train_v2.parquet \
#    data.val_files=/path/demo/genegene_copypaste_val_v2.parquet \
#    data.train_batch_size=8 \
#    data.max_prompt_length=40000 \
#    data.max_response_length=4000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_320_hg_gene2000_drop_original_rp/step_460_hg \
#    actor_rollout_ref.actor.optim.lr=2e-6 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_coef=0.02 \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.2 \
#    ++actor_rollout_ref.actor.optim.lr_scheduler=ReduceLROnPlateau \
#    ++actor_rollout_ref.actor.optim.lr_scheduler_kwargs.mode=max \
#    ++actor_rollout_ref.actor.optim.lr_scheduler_kwargs.factor=0.7 \
#    ++actor_rollout_ref.actor.optim.lr_scheduler_kwargs.patience=30 \
#    ++actor_rollout_ref.actor.optim.lr_scheduler_kwargs.threshold=-0.10 \
#    ++actor_rollout_ref.actor.optim.lr_scheduler_kwargs.min_lr=1e-7 \
#    ++trainer.metric_monitor=val_score \
#    actor_rollout_ref.actor.grad_clip=0.5 \
#    actor_rollout_ref.actor.entropy_coeff=0.02 \
#    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=True \
#    +actor_rollout_ref.ref.gpu_offload=True \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=4 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_460_hg_grpo_safe_lr_v2' \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=10 \
#    trainer.test_freq=10 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@


#python3 -m verl.trainer.main_ppo \
#    custom_reward_function.path=/path/demo/script/RL/reward_function_similarity.py \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_copypaste_train_v3.parquet \
#    data.val_files=/path/demo/genegene_copypaste_val_v3.parquet \
#    data.train_batch_size=8 \
#    data.max_prompt_length=40000 \
#    data.max_response_length=4000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_320_hg_gene2000_drop_original_rp/step_460_hg \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#    actor_rollout_ref.actor.optim.warmup_style=cosine \
#    actor_rollout_ref.actor.optim.total_training_steps=249 \
#    actor_rollout_ref.actor.optim.min_lr_ratio=0.0 \
#    actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#    actor_rollout_ref.actor.optim.clip_grad=0.5 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.kl_loss_coef=1.0 \
#    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=1.0 \
#    actor_rollout_ref.actor.grad_clip=0.1 \
#    actor_rollout_ref.actor.entropy_coeff=0.001 \
#    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=True \
#    +actor_rollout_ref.ref.gpu_offload=True \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=4 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_460_hg_grpo_copypaste_v3_test_lr_decay' \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=10 \
#    trainer.test_freq=10 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@

# g1
#python3 -m verl.trainer.main_ppo \
#    custom_reward_function.path=/path/demo/script/RL/reward_function_6_rewards.py \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_copypaste_train_v3.parquet \
#    data.val_files=/path/demo/genegene_copypaste_val_v3.parquet \
#    data.train_batch_size=8 \
#    data.max_prompt_length=40000 \
#    data.max_response_length=4000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_320_hg_gene2000_drop_original_rp/step_460_hg \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#    actor_rollout_ref.actor.optim.warmup_style=cosine \
#    actor_rollout_ref.actor.optim.total_training_steps=249 \
#    actor_rollout_ref.actor.optim.min_lr_ratio=0.0 \
#    actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#    actor_rollout_ref.actor.optim.clip_grad=1.0 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.kl_loss_coef=0.05 \
#    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.05 \
#    actor_rollout_ref.actor.grad_clip=1.0 \
#    actor_rollout_ref.actor.entropy_coeff=0.0001 \
#    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=True \
#    +actor_rollout_ref.ref.gpu_offload=True \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=4 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_460_hg_grpo_copypaste_v3_6_rewards_g2' \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=10 \
#    trainer.test_freq=10 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@

# g2
#export WANDB_PROJECT=verl_grpo_dna_assemble_3500
#python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
#export WANDB_MODE=offline
#
#python3 -m verl.trainer.main_ppo \
#    custom_reward_function.path=/path/demo/script/RL/reward_function_6_rewards.py \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_copypaste_train_v3.parquet \
#    data.val_files=/path/demo/genegene_copypaste_val_v3.parquet \
#    data.train_batch_size=8 \
#    data.max_prompt_length=40000 \
#    data.max_response_length=4000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_320_hg_gene2000_drop_original_rp/step_460_hg \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#    actor_rollout_ref.actor.optim.warmup_style=cosine \
#    actor_rollout_ref.actor.optim.total_training_steps=249 \
#    actor_rollout_ref.actor.optim.min_lr_ratio=0.0 \
#    actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#    actor_rollout_ref.actor.optim.clip_grad=0.7 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.kl_loss_coef=0.15 \
#    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.15 \
#    actor_rollout_ref.actor.grad_clip=0.7 \
#    actor_rollout_ref.actor.entropy_coeff=0.0002 \
#    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=True \
#    +actor_rollout_ref.ref.gpu_offload=True \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=4 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_460_hg_grpo_copypaste_v3_6_rewards_g2' \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=10 \
#    trainer.test_freq=10 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@

# g3
#export WANDB_PROJECT=verl_grpo_dna_assemble_3500
#python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
#export WANDB_MODE=offline
#
#python3 -m verl.trainer.main_ppo \
#    custom_reward_function.path=/path/demo/script/RL/reward_function_6_rewards.py \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_copypaste_train_v3.parquet \
#    data.val_files=/path/demo/genegene_copypaste_val_v3.parquet \
#    data.train_batch_size=8 \
#    data.max_prompt_length=40000 \
#    data.max_response_length=4000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_320_hg_gene2000_drop_original_rp/step_460_hg \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#    actor_rollout_ref.actor.optim.warmup_style=cosine \
#    actor_rollout_ref.actor.optim.total_training_steps=249 \
#    actor_rollout_ref.actor.optim.min_lr_ratio=0.0 \
#    actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#    actor_rollout_ref.actor.optim.clip_grad=0.5 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.kl_loss_coef=0.25 \
#    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
#    actor_rollout_ref.actor.grad_clip=0.5 \
#    actor_rollout_ref.actor.entropy_coeff=0.0004 \
#    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=True \
#    +actor_rollout_ref.ref.gpu_offload=True \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=4 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_460_hg_grpo_copypaste_v3_6_rewards_g3' \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=10 \
#    trainer.test_freq=10 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@

# g4

#export WANDB_PROJECT=verl_grpo_dna_assemble_3500
#python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
#export WANDB_MODE=offline
#
#
#python3 -m verl.trainer.main_ppo \
#    custom_reward_function.path=/path/demo/script/RL/reward_function_6_rewards.py \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_copypaste_train_v3.parquet \
#    data.val_files=/path/demo/genegene_copypaste_val_v3.parquet \
#    data.train_batch_size=8 \
#    data.max_prompt_length=40000 \
#    data.max_response_length=4000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_320_hg_gene2000_drop_original_rp/step_460_hg \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#    actor_rollout_ref.actor.optim.warmup_style=cosine \
#    actor_rollout_ref.actor.optim.total_training_steps=249 \
#    actor_rollout_ref.actor.optim.min_lr_ratio=0.0 \
#    actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#    actor_rollout_ref.actor.optim.clip_grad=0.3 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.kl_loss_coef=0.4 \
#    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.4 \
#    actor_rollout_ref.actor.grad_clip=0.3 \
#    actor_rollout_ref.actor.entropy_coeff=0.0006 \
#    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=True \
#    +actor_rollout_ref.ref.gpu_offload=True \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=4 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_460_hg_grpo_copypaste_v3_6_rewards_g4' \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=10 \
#    trainer.test_freq=10 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@


# g3-c460-a
#export WANDB_PROJECT=verl_grpo_dna_assemble_3500
#python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
#export WANDB_MODE=offline
#
#python3 -m verl.trainer.main_ppo \
#    custom_reward_function.path=/path/demo/script/RL/reward_function_linear_a.py \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_copypaste_train_v2.parquet \
#    data.val_files=/path/demo/genegene_copypaste_val_v2.parquet \
#    data.train_batch_size=8 \
#    data.max_prompt_length=40000 \
#    data.max_response_length=4000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_320_hg_gene2000_drop_original_rp/step_460_hg \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#    actor_rollout_ref.actor.optim.warmup_style=cosine \
#    actor_rollout_ref.actor.optim.total_training_steps=249 \
#    actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
#    actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#    actor_rollout_ref.actor.optim.clip_grad=0.5 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.kl_loss_coef=0.25 \
#    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
#    actor_rollout_ref.actor.grad_clip=0.5 \
#    actor_rollout_ref.actor.entropy_coeff=0.0004 \
#    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=True \
#    +actor_rollout_ref.ref.gpu_offload=True \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=4 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_460_hg_grpo_copypaste_v3_g3_c460_a' \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=10 \
#    trainer.test_freq=10 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@



# g3-c460-b
#export WANDB_PROJECT=verl_grpo_dna_assemble_3500
#python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
#export WANDB_MODE=offline
#
#python3 -m verl.trainer.main_ppo \
#    custom_reward_function.path=/path/demo/script/RL/reward_function_linear_b.py \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_copypaste_train_v2.parquet \
#    data.val_files=/path/demo/genegene_copypaste_val_v2.parquet \
#    data.train_batch_size=8 \
#    data.max_prompt_length=40000 \
#    data.max_response_length=4000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_320_hg_gene2000_drop_original_rp/step_460_hg \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#    actor_rollout_ref.actor.optim.warmup_style=cosine \
#    actor_rollout_ref.actor.optim.total_training_steps=249 \
#    actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
#    actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#    actor_rollout_ref.actor.optim.clip_grad=0.5 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.kl_loss_coef=0.25 \
#    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
#    actor_rollout_ref.actor.grad_clip=0.5 \
#    actor_rollout_ref.actor.entropy_coeff=0.0004 \
#    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=True \
#    +actor_rollout_ref.ref.gpu_offload=True \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=4 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_460_hg_grpo_copypaste_v3_g3_c460_b' \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=10 \
#    trainer.test_freq=10 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@


# g3-c460-c
#export WANDB_PROJECT=verl_grpo_dna_assemble_3500
#python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
#export WANDB_MODE=offline
#
#python3 -m verl.trainer.main_ppo \
#    custom_reward_function.path=/path/demo/script/RL/reward_function_linear_c.py \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_copypaste_train_v2.parquet \
#    data.val_files=/path/demo/genegene_copypaste_val_v2.parquet \
#    data.train_batch_size=8 \
#    data.max_prompt_length=40000 \
#    data.max_response_length=4000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_320_hg_gene2000_drop_original_rp/step_460_hg \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#    actor_rollout_ref.actor.optim.warmup_style=cosine \
#    actor_rollout_ref.actor.optim.total_training_steps=249 \
#    actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
#    actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#    actor_rollout_ref.actor.optim.clip_grad=0.5 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.kl_loss_coef=0.25 \
#    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
#    actor_rollout_ref.actor.grad_clip=0.5 \
#    actor_rollout_ref.actor.entropy_coeff=0.0004 \
#    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=True \
#    +actor_rollout_ref.ref.gpu_offload=True \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=4 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_460_hg_grpo_copypaste_v3_g3_c460_c' \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=10 \
#    trainer.test_freq=10 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@


# g3-c460-d
#export WANDB_PROJECT=verl_grpo_dna_assemble_3500
#python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
#export WANDB_MODE=offline
#
#python3 -m verl.trainer.main_ppo \
#    custom_reward_function.path=/path/demo/script/RL/reward_function_linear_d.py \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_copypaste_train_v2.parquet \
#    data.val_files=/path/demo/genegene_copypaste_val_v2.parquet \
#    data.train_batch_size=8 \
#    data.max_prompt_length=40000 \
#    data.max_response_length=4000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_320_hg_gene2000_drop_original_rp/step_460_hg \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#    actor_rollout_ref.actor.optim.warmup_style=cosine \
#    actor_rollout_ref.actor.optim.total_training_steps=249 \
#    actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
#    actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#    actor_rollout_ref.actor.optim.clip_grad=0.5 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.kl_loss_coef=0.25 \
#    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
#    actor_rollout_ref.actor.grad_clip=0.5 \
#    actor_rollout_ref.actor.entropy_coeff=0.0004 \
#    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=True \
#    +actor_rollout_ref.ref.gpu_offload=True \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=4 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_460_hg_grpo_copypaste_v3_g3_c460_d' \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=10 \
#    trainer.test_freq=10 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@


# g3-qwen-a
#export WANDB_PROJECT=verl_grpo_dna_assemble_3500
#python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
#export WANDB_MODE=offline
#
#python3 -m verl.trainer.main_ppo \
#    custom_reward_function.path=/path/demo/script/RL/reward_function_linear_a.py \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_copypaste_train_v2.parquet \
#    data.val_files=/path/demo/genegene_copypaste_val_v2.parquet \
#    data.train_batch_size=8 \
#    data.max_prompt_length=40000 \
#    data.max_response_length=4000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/model_weights/Qwen/Qwen3-4B-Instruct-2507 \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#    actor_rollout_ref.actor.optim.warmup_style=cosine \
#    actor_rollout_ref.actor.optim.total_training_steps=249 \
#    actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
#    actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#    actor_rollout_ref.actor.optim.clip_grad=0.5 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.kl_loss_coef=0.25 \
#    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
#    actor_rollout_ref.actor.grad_clip=0.5 \
#    actor_rollout_ref.actor.entropy_coeff=0.0004 \
#    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=True \
#    +actor_rollout_ref.ref.gpu_offload=True \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=4 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_460_hg_grpo_copypaste_v3_g3_qwen_a' \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=10 \
#    trainer.test_freq=10 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@


# g3-qwen-b
#export WANDB_PROJECT=verl_grpo_dna_assemble_3500
#python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
#export WANDB_MODE=offline
#
#python3 -m verl.trainer.main_ppo \
#    custom_reward_function.path=/path/demo/script/RL/reward_function_linear_b.py \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_copypaste_train_v2.parquet \
#    data.val_files=/path/demo/genegene_copypaste_val_v2.parquet \
#    data.train_batch_size=8 \
#    data.max_prompt_length=40000 \
#    data.max_response_length=4000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/model_weights/Qwen/Qwen3-4B-Instruct-2507 \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#    actor_rollout_ref.actor.optim.warmup_style=cosine \
#    actor_rollout_ref.actor.optim.total_training_steps=249 \
#    actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
#    actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#    actor_rollout_ref.actor.optim.clip_grad=0.5 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.kl_loss_coef=0.25 \
#    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
#    actor_rollout_ref.actor.grad_clip=0.5 \
#    actor_rollout_ref.actor.entropy_coeff=0.0004 \
#    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=True \
#    +actor_rollout_ref.ref.gpu_offload=True \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=4 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_460_hg_grpo_copypaste_v3_g3_qwen_b' \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=10 \
#    trainer.test_freq=10 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@


# g3-qwen-c
#export WANDB_PROJECT=verl_grpo_dna_assemble_3500
#python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
#export WANDB_MODE=offline
#
#python3 -m verl.trainer.main_ppo \
#    custom_reward_function.path=/path/demo/script/RL/reward_function_linear_c.py \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_copypaste_train_v2.parquet \
#    data.val_files=/path/demo/genegene_copypaste_val_v2.parquet \
#    data.train_batch_size=8 \
#    data.max_prompt_length=40000 \
#    data.max_response_length=4000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/model_weights/Qwen/Qwen3-4B-Instruct-2507 \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#    actor_rollout_ref.actor.optim.warmup_style=cosine \
#    actor_rollout_ref.actor.optim.total_training_steps=249 \
#    actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
#    actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#    actor_rollout_ref.actor.optim.clip_grad=0.5 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.kl_loss_coef=0.25 \
#    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
#    actor_rollout_ref.actor.grad_clip=0.5 \
#    actor_rollout_ref.actor.entropy_coeff=0.0004 \
#    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=True \
#    +actor_rollout_ref.ref.gpu_offload=True \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=4 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_460_hg_grpo_copypaste_v3_g3_qwen_c' \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=10 \
#    trainer.test_freq=10 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@


# g3-qwen-d
#export WANDB_PROJECT=verl_grpo_dna_assemble_3500
#python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
#export WANDB_MODE=offline
#
#python3 -m verl.trainer.main_ppo \
#    custom_reward_function.path=/path/demo/script/RL/reward_function_linear_d.py \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_copypaste_train_v2.parquet \
#    data.val_files=/path/demo/genegene_copypaste_val_v2.parquet \
#    data.train_batch_size=8 \
#    data.max_prompt_length=40000 \
#    data.max_response_length=4000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/model_weights/Qwen/Qwen3-4B-Instruct-2507 \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#    actor_rollout_ref.actor.optim.warmup_style=cosine \
#    actor_rollout_ref.actor.optim.total_training_steps=249 \
#    actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
#    actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#    actor_rollout_ref.actor.optim.clip_grad=0.5 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.kl_loss_coef=0.25 \
#    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
#    actor_rollout_ref.actor.grad_clip=0.5 \
#    actor_rollout_ref.actor.entropy_coeff=0.0004 \
#    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=True \
#    +actor_rollout_ref.ref.gpu_offload=True \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=4 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_460_hg_grpo_copypaste_v3_g3_qwen_d' \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=10 \
#    trainer.test_freq=10 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@


# target curve v2 online checkpoint overwritten invalid
#export WANDB_PROJECT=verl_grpo_dna_assemble_3500
#python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
##export WANDB_MODE=offline
#
#python3 -m verl.trainer.main_ppo \
#    reward_model.reward_manager=batch \
#    custom_reward_function.path=/path/demo/script/RL/reward_function_target_curve.py \
#    custom_reward_function.name=compute_score_batch \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_copypaste_train_v2.parquet \
#    data.val_files=/path/demo/genegene_copypaste_val_v2.parquet \
#    data.train_batch_size=8 \
#    data.max_prompt_length=40000 \
#    data.max_response_length=4000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_320_hg_gene2000_drop_original_rp/step_460_hg \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#    actor_rollout_ref.actor.optim.warmup_style=cosine \
#    actor_rollout_ref.actor.optim.total_training_steps=249 \
#    actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
#    actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#    actor_rollout_ref.actor.optim.clip_grad=0.5 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.kl_loss_coef=0.25 \
#    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
#    actor_rollout_ref.actor.grad_clip=0.5 \
#    actor_rollout_ref.actor.entropy_coeff=0.0004 \
#    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=True \
#    +actor_rollout_ref.ref.gpu_offload=True \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=4 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_460_hg_grpo_copypaste_v2_target_curve_online' \
#    trainer.default_local_dir=/path/demo/checkpoints \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=10 \
#    trainer.test_freq=10 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@


# equal weight v2
#export WANDB_PROJECT=verl_grpo_dna_assemble_3500
#python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
#export WANDB_MODE=offline
#
#python3 -m verl.trainer.main_ppo \
#    custom_reward_function.path=/path/demo/script/RL/reward_function_equal_weight.py \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_copypaste_train_v2.parquet \
#    data.val_files=/path/demo/genegene_copypaste_val_v2.parquet \
#    data.train_batch_size=8 \
#    data.max_prompt_length=40000 \
#    data.max_response_length=4000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_320_hg_gene2000_drop_original_rp/step_460_hg \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#    actor_rollout_ref.actor.optim.warmup_style=cosine \
#    actor_rollout_ref.actor.optim.total_training_steps=249 \
#    actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
#    actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#    actor_rollout_ref.actor.optim.clip_grad=0.5 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.kl_loss_coef=0.25 \
#    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
#    actor_rollout_ref.actor.grad_clip=0.5 \
#    actor_rollout_ref.actor.entropy_coeff=0.0004 \
#    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=True \
#    +actor_rollout_ref.ref.gpu_offload=True \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=4 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_460_hg_grpo_copypaste_v2_equal_weight' \
#    trainer.default_local_dir=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_460_hg_grpo_copypaste_v2_equal_weight \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=10 \
#    trainer.test_freq=10 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@

# equal weight v5
#export WANDB_PROJECT=verl_grpo_dna_assemble_3500
#python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
#export WANDB_MODE=offline
#
#python3 -m verl.trainer.main_ppo \
#    custom_reward_function.path=/path/demo/script/RL/reward_function_equal_weight.py \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_copypaste_train_v5.parquet \
#    data.val_files=/path/demo/genegene_copypaste_val_v5.parquet \
#    data.train_batch_size=8 \
#    data.max_prompt_length=40000 \
#    data.max_response_length=4000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_320_hg_gene2000_drop_original_rp/step_460_hg \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#    actor_rollout_ref.actor.optim.warmup_style=cosine \
#    actor_rollout_ref.actor.optim.total_training_steps=249 \
#    actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
#    actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#    actor_rollout_ref.actor.optim.clip_grad=0.5 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.kl_loss_coef=0.25 \
#    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
#    actor_rollout_ref.actor.grad_clip=0.5 \
#    actor_rollout_ref.actor.entropy_coeff=0.0004 \
#    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=True \
#    +actor_rollout_ref.ref.gpu_offload=True \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=4 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_460_hg_grpo_copypaste_v5_equal_weight' \
#    trainer.default_local_dir=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_460_hg_grpo_copypaste_v5_equal_weight \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=10 \
#    trainer.test_freq=10 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@


# batch random v2
#export WANDB_PROJECT=verl_grpo_dna_assemble_3500
#python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
#export WANDB_MODE=offline
#
#python3 -m verl.trainer.main_ppo \
#    reward_model.reward_manager=batch \
#    custom_reward_function.path=/path/demo/script/RL/reward_function_batch_random.py \
#    custom_reward_function.name=compute_score_batch \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_copypaste_train_v2.parquet \
#    data.val_files=/path/demo/genegene_copypaste_val_v2.parquet \
#    data.train_batch_size=8 \
#    data.max_prompt_length=40000 \
#    data.max_response_length=4000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_320_hg_gene2000_drop_original_rp/step_460_hg \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#    actor_rollout_ref.actor.optim.warmup_style=cosine \
#    actor_rollout_ref.actor.optim.total_training_steps=249 \
#    actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
#    actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#    actor_rollout_ref.actor.optim.clip_grad=0.5 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.kl_loss_coef=0.25 \
#    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
#    actor_rollout_ref.actor.grad_clip=0.5 \
#    actor_rollout_ref.actor.entropy_coeff=0.0004 \
#    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=True \
#    +actor_rollout_ref.ref.gpu_offload=True \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=4 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_460_hg_grpo_copypaste_v2_batch_random' \
#    trainer.default_local_dir=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_460_hg_grpo_copypaste_v2_batch_random \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=10 \
#    trainer.test_freq=10 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@


# batch random v5
#export WANDB_PROJECT=verl_grpo_dna_assemble_3500
#python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
#export WANDB_MODE=offline
#
#python3 -m verl.trainer.main_ppo \
#    reward_model.reward_manager=batch \
#    custom_reward_function.path=/path/demo/script/RL/reward_function_batch_random.py \
#    custom_reward_function.name=compute_score_batch \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_copypaste_train_v5.parquet \
#    data.val_files=/path/demo/genegene_copypaste_val_v5.parquet \
#    data.train_batch_size=8 \
#    data.max_prompt_length=40000 \
#    data.max_response_length=4000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_320_hg_gene2000_drop_original_rp/step_460_hg \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#    actor_rollout_ref.actor.optim.warmup_style=cosine \
#    actor_rollout_ref.actor.optim.total_training_steps=249 \
#    actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
#    actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#    actor_rollout_ref.actor.optim.clip_grad=0.5 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.kl_loss_coef=0.25 \
#    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
#    actor_rollout_ref.actor.grad_clip=0.5 \
#    actor_rollout_ref.actor.entropy_coeff=0.0004 \
#    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=True \
#    +actor_rollout_ref.ref.gpu_offload=True \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=4 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_460_hg_grpo_copypaste_v5_batch_random' \
#    trainer.default_local_dir=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_460_hg_grpo_copypaste_v5_batch_random \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=10 \
#    trainer.test_freq=10 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@

# target curve v2
#export WANDB_PROJECT=verl_grpo_dna_assemble_3500
#python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
#export WANDB_MODE=offline
#
#python3 -m verl.trainer.main_ppo \
#    reward_model.reward_manager=batch \
#    custom_reward_function.path=/path/demo/script/RL/reward_function_target_curve.py \
#    custom_reward_function.name=compute_score_batch \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_copypaste_train_v2.parquet \
#    data.val_files=/path/demo/genegene_copypaste_val_v2.parquet \
#    data.train_batch_size=8 \
#    data.max_prompt_length=40000 \
#    data.max_response_length=4000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_320_hg_gene2000_drop_original_rp/step_460_hg \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#    actor_rollout_ref.actor.optim.warmup_style=cosine \
#    actor_rollout_ref.actor.optim.total_training_steps=249 \
#    actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
#    actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#    actor_rollout_ref.actor.optim.clip_grad=0.5 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.kl_loss_coef=0.25 \
#    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
#    actor_rollout_ref.actor.grad_clip=0.5 \
#    actor_rollout_ref.actor.entropy_coeff=0.0004 \
#    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=True \
#    +actor_rollout_ref.ref.gpu_offload=True \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=4 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_460_hg_grpo_copypaste_v2_target_curve' \
#    trainer.default_local_dir=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_460_hg_grpo_copypaste_v2_target_curve \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=10 \
#    trainer.test_freq=10 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@


# target curve v5
#export WANDB_PROJECT=verl_grpo_dna_assemble_3500
#python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
#export WANDB_MODE=offline
#
#python3 -m verl.trainer.main_ppo \
#    reward_model.reward_manager=batch \
#    custom_reward_function.path=/path/demo/script/RL/reward_function_target_curve.py \
#    custom_reward_function.name=compute_score_batch \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_copypaste_train_v5.parquet \
#    data.val_files=/path/demo/genegene_copypaste_val_v5.parquet \
#    data.train_batch_size=8 \
#    data.max_prompt_length=40000 \
#    data.max_response_length=4000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_320_hg_gene2000_drop_original_rp/step_460_hg \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#    actor_rollout_ref.actor.optim.warmup_style=cosine \
#    actor_rollout_ref.actor.optim.total_training_steps=249 \
#    actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
#    actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#    actor_rollout_ref.actor.optim.clip_grad=0.5 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.kl_loss_coef=0.25 \
#    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
#    actor_rollout_ref.actor.grad_clip=0.5 \
#    actor_rollout_ref.actor.entropy_coeff=0.0004 \
#    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=True \
#    +actor_rollout_ref.ref.gpu_offload=True \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=4 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_460_hg_grpo_copypaste_v5_target_curve' \
#    trainer.default_local_dir=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_460_hg_grpo_copypaste_v5_target_curve \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=10 \
#    trainer.test_freq=10 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@


# target curve v6 3A0B  1A3B
#export WANDB_PROJECT=verl_grpo_dna_assemble_3500
#python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
##export WANDB_MODE=offline
#
#python3 -m verl.trainer.main_ppo \
#    reward_model.reward_manager=batch \
#    custom_reward_function.path=/path/demo/script/RL/reward_function_target_curve.py \
#    custom_reward_function.name=compute_score_batch \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_copypaste_train_v6.parquet \
#    data.val_files=/path/demo/genegene_copypaste_val_v6.parquet \
#    data.train_batch_size=8 \
#    data.max_prompt_length=40000 \
#    data.max_response_length=4000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_320_hg_gene2000_drop_original_rp/step_460_hg \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#    actor_rollout_ref.actor.optim.warmup_style=cosine \
#    actor_rollout_ref.actor.optim.total_training_steps=249 \
#    actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
#    actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#    actor_rollout_ref.actor.optim.clip_grad=0.5 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.kl_loss_coef=0.25 \
#    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
#    actor_rollout_ref.actor.grad_clip=0.5 \
#    actor_rollout_ref.actor.entropy_coeff=0.0004 \
#    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=True \
#    +actor_rollout_ref.ref.gpu_offload=True \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=4 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_460_hg_grpo_copypaste_v6_target_curve' \
#    trainer.default_local_dir=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_460_hg_grpo_copypaste_v6_target_curve \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=10 \
#    trainer.test_freq=10 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@



# step_210_ew_grpo_copypaste_v6_ew 3A0B  0A3B  1A3B

#export WANDB_PROJECT=verl_grpo_dna_assemble_3500
#python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
#export WANDB_MODE=offline
#
#python3 -m verl.trainer.main_ppo \
#    custom_reward_function.path=/path/demo/script/RL/reward_function_equal_weight.py \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_copypaste_train_v6.parquet \
#    data.val_files=/path/demo/genegene_copypaste_val_v6.parquet \
#    data.train_batch_size=8 \
#    data.max_prompt_length=40000 \
#    data.max_response_length=4000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_460_hg_grpo_copypaste_v5_equal_weight/step_210_hg \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#    actor_rollout_ref.actor.optim.warmup_style=cosine \
#    actor_rollout_ref.actor.optim.total_training_steps=249 \
#    actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
#    actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#    actor_rollout_ref.actor.optim.clip_grad=0.5 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.kl_loss_coef=0.25 \
#    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
#    actor_rollout_ref.actor.grad_clip=0.5 \
#    actor_rollout_ref.actor.entropy_coeff=0.0004 \
#    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=True \
#    +actor_rollout_ref.ref.gpu_offload=True \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=4 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_210_ew_grpo_copypaste_v6_ew' \
#    trainer.default_local_dir=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_210_ew_grpo_copypaste_v6_ew \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=10 \
#    trainer.test_freq=10 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@

# step_210_ew_grpo_copypaste_v6_br 3A0B  0A3B  1A3B

#export WANDB_PROJECT=verl_grpo_dna_assemble_3500
#python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
#export WANDB_MODE=offline
#
#python3 -m verl.trainer.main_ppo \
#    reward_model.reward_manager=batch \
#    custom_reward_function.path=/path/demo/script/RL/reward_function_batch_random.py \
#    custom_reward_function.name=compute_score_batch \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_copypaste_train_v6.parquet \
#    data.val_files=/path/demo/genegene_copypaste_val_v6.parquet \
#    data.train_batch_size=8 \
#    data.max_prompt_length=40000 \
#    data.max_response_length=4000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_460_hg_grpo_copypaste_v5_equal_weight/step_210_hg \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#    actor_rollout_ref.actor.optim.warmup_style=cosine \
#    actor_rollout_ref.actor.optim.total_training_steps=249 \
#    actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
#    actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#    actor_rollout_ref.actor.optim.clip_grad=0.5 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.kl_loss_coef=0.25 \
#    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
#    actor_rollout_ref.actor.grad_clip=0.5 \
#    actor_rollout_ref.actor.entropy_coeff=0.0004 \
#    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=True \
#    +actor_rollout_ref.ref.gpu_offload=True \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=4 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_210_ew_grpo_copypaste_v6_br' \
#    trainer.default_local_dir=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_210_ew_grpo_copypaste_v6_br \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=10 \
#    trainer.test_freq=10 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@


# step_210_ew_grpo_copypaste_v6_tc 3A0B  0A3B  1A3B
#export WANDB_PROJECT=verl_grpo_dna_assemble_3500
#python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
#export WANDB_MODE=offline
#
#python3 -m verl.trainer.main_ppo \
#    reward_model.reward_manager=batch \
#    custom_reward_function.path=/path/demo/script/RL/reward_function_target_curve.py \
#    custom_reward_function.name=compute_score_batch \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_copypaste_train_v6.parquet \
#    data.val_files=/path/demo/genegene_copypaste_val_v6.parquet \
#    data.train_batch_size=8 \
#    data.max_prompt_length=40000 \
#    data.max_response_length=4000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_460_hg_grpo_copypaste_v5_equal_weight/step_210_hg \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#    actor_rollout_ref.actor.optim.warmup_style=cosine \
#    actor_rollout_ref.actor.optim.total_training_steps=249 \
#    actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
#    actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#    actor_rollout_ref.actor.optim.clip_grad=0.5 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.kl_loss_coef=0.25 \
#    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
#    actor_rollout_ref.actor.grad_clip=0.5 \
#    actor_rollout_ref.actor.entropy_coeff=0.0004 \
#    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=True \
#    +actor_rollout_ref.ref.gpu_offload=True \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=4 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_210_ew_grpo_copypaste_v6_tc' \
#    trainer.default_local_dir=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_210_ew_grpo_copypaste_v6_tc \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=10 \
#    trainer.test_freq=10 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@

# step_190_br_grpo_copypaste_v6_ew 3A0B  0A3B  1A3B
#export WANDB_PROJECT=verl_grpo_dna_assemble_3500
#python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
#export WANDB_MODE=offline
#
#python3 -m verl.trainer.main_ppo \
#    custom_reward_function.path=/path/demo/script/RL/reward_function_equal_weight.py \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_copypaste_train_v6.parquet \
#    data.val_files=/path/demo/genegene_copypaste_val_v6.parquet \
#    data.train_batch_size=8 \
#    data.max_prompt_length=40000 \
#    data.max_response_length=4000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_460_hg_grpo_copypaste_v5_batch_random/step_190_hg \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#    actor_rollout_ref.actor.optim.warmup_style=cosine \
#    actor_rollout_ref.actor.optim.total_training_steps=249 \
#    actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
#    actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#    actor_rollout_ref.actor.optim.clip_grad=0.5 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.kl_loss_coef=0.25 \
#    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
#    actor_rollout_ref.actor.grad_clip=0.5 \
#    actor_rollout_ref.actor.entropy_coeff=0.0004 \
#    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=True \
#    +actor_rollout_ref.ref.gpu_offload=True \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=4 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_190_br_grpo_copypaste_v6_ew' \
#    trainer.default_local_dir=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_190_br_grpo_copypaste_v6_ew \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=10 \
#    trainer.test_freq=10 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@

# step_190_br_grpo_copypaste_v6_br 3A0B  0A3B  1A3B
#export WANDB_PROJECT=verl_grpo_dna_assemble_3500
#python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
#export WANDB_MODE=offline
#
#python3 -m verl.trainer.main_ppo \
#    reward_model.reward_manager=batch \
#    custom_reward_function.path=/path/demo/script/RL/reward_function_batch_random.py \
#    custom_reward_function.name=compute_score_batch \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_copypaste_train_v6.parquet \
#    data.val_files=/path/demo/genegene_copypaste_val_v6.parquet \
#    data.train_batch_size=8 \
#    data.max_prompt_length=40000 \
#    data.max_response_length=4000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_460_hg_grpo_copypaste_v5_batch_random/step_190_hg \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#    actor_rollout_ref.actor.optim.warmup_style=cosine \
#    actor_rollout_ref.actor.optim.total_training_steps=249 \
#    actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
#    actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#    actor_rollout_ref.actor.optim.clip_grad=0.5 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.kl_loss_coef=0.25 \
#    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
#    actor_rollout_ref.actor.grad_clip=0.5 \
#    actor_rollout_ref.actor.entropy_coeff=0.0004 \
#    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=True \
#    +actor_rollout_ref.ref.gpu_offload=True \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=4 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_190_br_grpo_copypaste_v6_br' \
#    trainer.default_local_dir=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_190_br_grpo_copypaste_v6_br \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=10 \
#    trainer.test_freq=10 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@

# step_190_br_grpo_copypaste_v6_tc 3A0B  0A3B  1A3B
#export WANDB_PROJECT=verl_grpo_dna_assemble_3500
#python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
#export WANDB_MODE=offline
#
#python3 -m verl.trainer.main_ppo \
#    reward_model.reward_manager=batch \
#    custom_reward_function.path=/path/demo/script/RL/reward_function_target_curve.py \
#    custom_reward_function.name=compute_score_batch \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_copypaste_train_v6.parquet \
#    data.val_files=/path/demo/genegene_copypaste_val_v6.parquet \
#    data.train_batch_size=8 \
#    data.max_prompt_length=40000 \
#    data.max_response_length=4000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_460_hg_grpo_copypaste_v5_batch_random/step_190_hg \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#    actor_rollout_ref.actor.optim.warmup_style=cosine \
#    actor_rollout_ref.actor.optim.total_training_steps=249 \
#    actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
#    actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#    actor_rollout_ref.actor.optim.clip_grad=0.5 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.kl_loss_coef=0.25 \
#    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
#    actor_rollout_ref.actor.grad_clip=0.5 \
#    actor_rollout_ref.actor.entropy_coeff=0.0004 \
#    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=True \
#    +actor_rollout_ref.ref.gpu_offload=True \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=4 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_190_br_grpo_copypaste_v6_tc' \
#    trainer.default_local_dir=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_190_br_grpo_copypaste_v6_tc \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=10 \
#    trainer.test_freq=10 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@



# step_250_ew_ew_grpo_copypaste_v7_ew 3A0B  0A3B  1A3B  2A3B
#export WANDB_PROJECT=verl_grpo_dna_assemble_3500
#python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
##export WANDB_MODE=offline
#
#python3 -m verl.trainer.main_ppo \
#    custom_reward_function.path=/path/demo/script/RL/reward_function_equal_weight.py \
#    algorithm.adv_estimator=grpo \
#    data.train_files=/path/demo/genegene_copypaste_train_v7.parquet \
#    data.val_files=/path/demo/genegene_copypaste_val_v7.parquet \
#    data.train_batch_size=8 \
#    data.max_prompt_length=40000 \
#    data.max_response_length=4000 \
#    data.filter_overlong_prompts=True \
#    data.truncation='error' \
#    actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_210_ew_grpo_copypaste_v6_ew/step_250_hg \
#    actor_rollout_ref.actor.optim.lr=1e-6 \
#    actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#    actor_rollout_ref.actor.optim.warmup_style=cosine \
#    actor_rollout_ref.actor.optim.total_training_steps=249 \
#    actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
#    actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#    actor_rollout_ref.actor.optim.clip_grad=0.5 \
#    actor_rollout_ref.model.use_remove_padding=True \
#    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#    actor_rollout_ref.actor.use_kl_loss=True \
#    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#    actor_rollout_ref.actor.kl_loss_coef=0.25 \
#    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
#    actor_rollout_ref.actor.grad_clip=0.5 \
#    actor_rollout_ref.actor.entropy_coeff=0.0004 \
#    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#    actor_rollout_ref.model.enable_gradient_checkpointing=True \
#    actor_rollout_ref.actor.fsdp_config.param_offload=True \
#    +actor_rollout_ref.ref.gpu_offload=True \
#    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#    actor_rollout_ref.rollout.name=vllm \
#    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#    actor_rollout_ref.rollout.top_p=0.8 \
#    actor_rollout_ref.rollout.top_k=20 \
#    actor_rollout_ref.rollout.n=4 \
#    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#    actor_rollout_ref.ref.fsdp_config.param_offload=True \
#    algorithm.use_kl_in_reward=False \
#    trainer.critic_warmup=0 \
#    trainer.logger='["console","wandb"]' \
#    trainer.project_name='verl_grpo_dna_assemble_3500' \
#    trainer.experiment_name='step_250_ew_ew_grpo_copypaste_v7_ew' \
#    trainer.default_local_dir=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_250_ew_ew_grpo_copypaste_v7_ew \
#    trainer.n_gpus_per_node=4 \
#    trainer.nnodes=1 \
#    trainer.save_freq=10 \
#    trainer.test_freq=10 \
#    trainer.log_val_generations=50 \
#    trainer.total_epochs=1 $@



# Extra experiment: step_460_hg_grpo_copypaste_v6_equal_weight
# export WANDB_PROJECT=verl_grpo_dna_assemble_3500
# python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
# #export WANDB_MODE=offline

# python3 -m verl.trainer.main_ppo \
#     custom_reward_function.path=/path/demo/script/RL/reward_function_equal_weight.py \
#     algorithm.adv_estimator=grpo \
#     data.train_files=/path/demo/genegene_copypaste_train_v6.parquet \
#     data.val_files=/path/demo/genegene_copypaste_val_v6.parquet \
#     data.train_batch_size=8 \
#     data.max_prompt_length=40000 \
#     data.max_response_length=4000 \
#     data.filter_overlong_prompts=True \
#     data.truncation='error' \
#     actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_320_hg_gene2000_drop_original_rp/step_460_hg \
#     actor_rollout_ref.actor.optim.lr=1e-6 \
#     actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#     actor_rollout_ref.actor.optim.warmup_style=cosine \
#     actor_rollout_ref.actor.optim.total_training_steps=249 \
#     actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
#     actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#     actor_rollout_ref.actor.optim.clip_grad=0.5 \
#     actor_rollout_ref.model.use_remove_padding=True \
#     actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#     actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#     actor_rollout_ref.actor.use_kl_loss=True \
#     actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#     actor_rollout_ref.actor.kl_loss_coef=0.25 \
#     ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
#     actor_rollout_ref.actor.grad_clip=0.5 \
#     actor_rollout_ref.actor.entropy_coeff=0.0004 \
#     ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#     actor_rollout_ref.model.enable_gradient_checkpointing=True \
#     actor_rollout_ref.actor.fsdp_config.param_offload=True \
#     +actor_rollout_ref.ref.gpu_offload=True \
#     actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#     actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#     actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#     actor_rollout_ref.rollout.name=vllm \
#     actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#     actor_rollout_ref.rollout.top_p=0.8 \
#     actor_rollout_ref.rollout.top_k=20 \
#     actor_rollout_ref.rollout.n=4 \
#     actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#     ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#     +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#     actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#     actor_rollout_ref.ref.fsdp_config.param_offload=True \
#     algorithm.use_kl_in_reward=False \
#     trainer.critic_warmup=0 \
#     trainer.logger='["console","wandb"]' \
#     trainer.project_name='verl_grpo_dna_assemble_3500' \
#     trainer.experiment_name='step_460_hg_grpo_copypaste_v6_equal_weight_online' \
#     trainer.default_local_dir=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_460_hg_grpo_copypaste_v6_equal_weight_online \
#     trainer.n_gpus_per_node=4 \
#     trainer.nnodes=1 \
#     trainer.save_freq=10 \
#     trainer.test_freq=10 \
#     trainer.log_val_generations=50 \
#     trainer.total_epochs=1 $@

# v7-brwandb sync /path/demo/wandb/offline-run-20251201_104807-omvbjtd0done
# step_250_ew_ew_grpo_copypaste_v7_br 3A0B  0A3B  1A3B  2A3B
# export WANDB_PROJECT=verl_grpo_dna_assemble_3500
# python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
# export WANDB_MODE=offline

# python3 -m verl.trainer.main_ppo \
#     reward_model.reward_manager=batch \
#     custom_reward_function.path=/path/demo/script/RL/reward_function_batch_random.py \
#     custom_reward_function.name=compute_score_batch \
#     algorithm.adv_estimator=grpo \
#     data.train_files=/path/demo/genegene_copypaste_train_v7.parquet \
#     data.val_files=/path/demo/genegene_copypaste_val_v7.parquet \
#     data.train_batch_size=8 \
#     data.max_prompt_length=40000 \
#     data.max_response_length=4000 \
#     data.filter_overlong_prompts=True \
#     data.truncation='error' \
#     actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_210_ew_grpo_copypaste_v6_ew/step_250_hg \
#     actor_rollout_ref.actor.optim.lr=1e-6 \
#     actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#     actor_rollout_ref.actor.optim.warmup_style=cosine \
#     actor_rollout_ref.actor.optim.total_training_steps=249 \
#     actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
#     actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#     actor_rollout_ref.actor.optim.clip_grad=0.5 \
#     actor_rollout_ref.model.use_remove_padding=True \
#     actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#     actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#     actor_rollout_ref.actor.use_kl_loss=True \
#     actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#     actor_rollout_ref.actor.kl_loss_coef=0.25 \
#     ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
#     actor_rollout_ref.actor.grad_clip=0.5 \
#     actor_rollout_ref.actor.entropy_coeff=0.0004 \
#     ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#     actor_rollout_ref.model.enable_gradient_checkpointing=True \
#     actor_rollout_ref.actor.fsdp_config.param_offload=True \
#     +actor_rollout_ref.ref.gpu_offload=True \
#     actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#     actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#     actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#     actor_rollout_ref.rollout.name=vllm \
#     actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#     actor_rollout_ref.rollout.top_p=0.8 \
#     actor_rollout_ref.rollout.top_k=20 \
#     actor_rollout_ref.rollout.n=4 \
#     actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#     ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#     +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#     actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#     actor_rollout_ref.ref.fsdp_config.param_offload=True \
#     algorithm.use_kl_in_reward=False \
#     trainer.critic_warmup=0 \
#     trainer.logger='["console","wandb"]' \
#     trainer.project_name='verl_grpo_dna_assemble_3500' \
#     trainer.experiment_name='step_250_ew_ew_grpo_copypaste_v7_br' \
#     trainer.default_local_dir=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_250_ew_ew_grpo_copypaste_v7_br \
#     trainer.n_gpus_per_node=4 \
#     trainer.nnodes=1 \
#     trainer.save_freq=10 \
#     trainer.test_freq=10 \
#     trainer.log_val_generations=50 \
#     trainer.total_epochs=1 $@


# v7-tcwandb sync /path/demo/wandb/offline-run-20251128_163347-12ys7bksdone
# step_250_ew_ew_grpo_copypaste_v7_tc 3A0B  0A3B  1A3B  2A3B
# export WANDB_PROJECT=verl_grpo_dna_assemble_3500
# python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
# export WANDB_MODE=offline

# python3 -m verl.trainer.main_ppo \
#     reward_model.reward_manager=batch \
#     custom_reward_function.path=/path/demo/script/RL/reward_function_target_curve.py \
#     custom_reward_function.name=compute_score_batch \
#     algorithm.adv_estimator=grpo \
#     data.train_files=/path/demo/genegene_copypaste_train_v7.parquet \
#     data.val_files=/path/demo/genegene_copypaste_val_v7.parquet \
#     data.train_batch_size=8 \
#     data.max_prompt_length=40000 \
#     data.max_response_length=4000 \
#     data.filter_overlong_prompts=True \
#     data.truncation='error' \
#     actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_210_ew_grpo_copypaste_v6_ew/step_250_hg \
#     actor_rollout_ref.actor.optim.lr=1e-6 \
#     actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#     actor_rollout_ref.actor.optim.warmup_style=cosine \
#     actor_rollout_ref.actor.optim.total_training_steps=249 \
#     actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
#     actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#     actor_rollout_ref.actor.optim.clip_grad=0.5 \
#     actor_rollout_ref.model.use_remove_padding=True \
#     actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#     actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#     actor_rollout_ref.actor.use_kl_loss=True \
#     actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#     actor_rollout_ref.actor.kl_loss_coef=0.25 \
#     ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
#     actor_rollout_ref.actor.grad_clip=0.5 \
#     actor_rollout_ref.actor.entropy_coeff=0.0004 \
#     ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#     actor_rollout_ref.model.enable_gradient_checkpointing=True \
#     actor_rollout_ref.actor.fsdp_config.param_offload=True \
#     +actor_rollout_ref.ref.gpu_offload=True \
#     actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#     actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#     actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#     actor_rollout_ref.rollout.name=vllm \
#     actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#     actor_rollout_ref.rollout.top_p=0.8 \
#     actor_rollout_ref.rollout.top_k=20 \
#     actor_rollout_ref.rollout.n=4 \
#     actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#     ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#     +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#     actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#     actor_rollout_ref.ref.fsdp_config.param_offload=True \
#     algorithm.use_kl_in_reward=False \
#     trainer.critic_warmup=0 \
#     trainer.logger='["console","wandb"]' \
#     trainer.project_name='verl_grpo_dna_assemble_3500' \
#     trainer.experiment_name='step_250_ew_ew_grpo_copypaste_v7_tc' \
#     trainer.default_local_dir=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_250_ew_ew_grpo_copypaste_v7_tc \
#     trainer.n_gpus_per_node=4 \
#     trainer.nnodes=1 \
#     trainer.save_freq=10 \
#     trainer.test_freq=10 \
#     trainer.log_val_generations=50 \
#     trainer.total_epochs=1 $@


# v8-ewwandb sync /path/demo/wandb/offline-run-20251128_045212-xuyw3dm8done
# step_250_ew_ew_grpo_copypaste_v8_ew 3A0B  0A3B  1A3B  1.5A3B
# export WANDB_PROJECT=verl_grpo_dna_assemble_3500
# python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
# export WANDB_MODE=offline

# python3 -m verl.trainer.main_ppo \
#     custom_reward_function.path=/path/demo/script/RL/reward_function_equal_weight.py \
#     algorithm.adv_estimator=grpo \
#     data.train_files=/path/demo/genegene_copypaste_train_v8.parquet \
#     data.val_files=/path/demo/genegene_copypaste_val_v8.parquet \
#     data.train_batch_size=8 \
#     data.max_prompt_length=40000 \
#     data.max_response_length=4000 \
#     data.filter_overlong_prompts=True \
#     data.truncation='error' \
#     actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_210_ew_grpo_copypaste_v6_ew/step_250_hg \
#     actor_rollout_ref.actor.optim.lr=1e-6 \
#     actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#     actor_rollout_ref.actor.optim.warmup_style=cosine \
#     actor_rollout_ref.actor.optim.total_training_steps=249 \
#     actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
#     actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#     actor_rollout_ref.actor.optim.clip_grad=0.5 \
#     actor_rollout_ref.model.use_remove_padding=True \
#     actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#     actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#     actor_rollout_ref.actor.use_kl_loss=True \
#     actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#     actor_rollout_ref.actor.kl_loss_coef=0.25 \
#     ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
#     actor_rollout_ref.actor.grad_clip=0.5 \
#     actor_rollout_ref.actor.entropy_coeff=0.0004 \
#     ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#     actor_rollout_ref.model.enable_gradient_checkpointing=True \
#     actor_rollout_ref.actor.fsdp_config.param_offload=True \
#     +actor_rollout_ref.ref.gpu_offload=True \
#     actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#     actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#     actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#     actor_rollout_ref.rollout.name=vllm \
#     actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#     actor_rollout_ref.rollout.top_p=0.8 \
#     actor_rollout_ref.rollout.top_k=20 \
#     actor_rollout_ref.rollout.n=4 \
#     actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#     ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#     +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#     actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#     actor_rollout_ref.ref.fsdp_config.param_offload=True \
#     algorithm.use_kl_in_reward=False \
#     trainer.critic_warmup=0 \
#     trainer.logger='["console","wandb"]' \
#     trainer.project_name='verl_grpo_dna_assemble_3500' \
#     trainer.experiment_name='step_250_ew_ew_grpo_copypaste_v8_ew' \
#     trainer.default_local_dir=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_250_ew_ew_grpo_copypaste_v8_ew \
#     trainer.n_gpus_per_node=4 \
#     trainer.nnodes=1 \
#     trainer.save_freq=10 \
#     trainer.test_freq=10 \
#     trainer.log_val_generations=50 \
#     trainer.total_epochs=1 $@


# v8-brwandb sync /path/demo/wandb/offline-run-20251126_112116-0job82o7done
# step_250_ew_ew_grpo_copypaste_v8_br 3A0B  0A3B  1A3B  1.5A3B
# export WANDB_PROJECT=verl_grpo_dna_assemble_3500
# python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
# export WANDB_MODE=offline

# python3 -m verl.trainer.main_ppo \
#     reward_model.reward_manager=batch \
#     custom_reward_function.path=/path/demo/script/RL/reward_function_batch_random.py \
#     custom_reward_function.name=compute_score_batch \
#     algorithm.adv_estimator=grpo \
#     data.train_files=/path/demo/genegene_copypaste_train_v8.parquet \
#     data.val_files=/path/demo/genegene_copypaste_val_v8.parquet \
#     data.train_batch_size=8 \
#     data.max_prompt_length=40000 \
#     data.max_response_length=4000 \
#     data.filter_overlong_prompts=True \
#     data.truncation='error' \
#     actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_210_ew_grpo_copypaste_v6_ew/step_250_hg \
#     actor_rollout_ref.actor.optim.lr=1e-6 \
#     actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#     actor_rollout_ref.actor.optim.warmup_style=cosine \
#     actor_rollout_ref.actor.optim.total_training_steps=249 \
#     actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
#     actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#     actor_rollout_ref.actor.optim.clip_grad=0.5 \
#     actor_rollout_ref.model.use_remove_padding=True \
#     actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#     actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#     actor_rollout_ref.actor.use_kl_loss=True \
#     actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#     actor_rollout_ref.actor.kl_loss_coef=0.25 \
#     ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
#     actor_rollout_ref.actor.grad_clip=0.5 \
#     actor_rollout_ref.actor.entropy_coeff=0.0004 \
#     ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#     actor_rollout_ref.model.enable_gradient_checkpointing=True \
#     actor_rollout_ref.actor.fsdp_config.param_offload=True \
#     +actor_rollout_ref.ref.gpu_offload=True \
#     actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#     actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#     actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#     actor_rollout_ref.rollout.name=vllm \
#     actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#     actor_rollout_ref.rollout.top_p=0.8 \
#     actor_rollout_ref.rollout.top_k=20 \
#     actor_rollout_ref.rollout.n=4 \
#     actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#     ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#     +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#     actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#     actor_rollout_ref.ref.fsdp_config.param_offload=True \
#     algorithm.use_kl_in_reward=False \
#     trainer.critic_warmup=0 \
#     trainer.logger='["console","wandb"]' \
#     trainer.project_name='verl_grpo_dna_assemble_3500' \
#     trainer.experiment_name='step_250_ew_ew_grpo_copypaste_v8_br' \
#     trainer.default_local_dir=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_250_ew_ew_grpo_copypaste_v8_br \
#     trainer.n_gpus_per_node=4 \
#     trainer.nnodes=1 \
#     trainer.save_freq=10 \
#     trainer.test_freq=10 \
#     trainer.log_val_generations=50 \
#     trainer.total_epochs=1 $@


# v8-tcwandb sync /path/demo/wandb/offline-run-20251126_234909-v5vi3zdddone
# step_250_ew_ew_grpo_copypaste_v8_tc 3A0B  0A3B  1A3B  1.5A3B
# export WANDB_PROJECT=verl_grpo_dna_assemble_3500
# python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
# export WANDB_MODE=offline

# python3 -m verl.trainer.main_ppo \
#     reward_model.reward_manager=batch \
#     custom_reward_function.path=/path/demo/script/RL/reward_function_target_curve.py \
#     custom_reward_function.name=compute_score_batch \
#     algorithm.adv_estimator=grpo \
#     data.train_files=/path/demo/genegene_copypaste_train_v8.parquet \
#     data.val_files=/path/demo/genegene_copypaste_val_v8.parquet \
#     data.train_batch_size=8 \
#     data.max_prompt_length=40000 \
#     data.max_response_length=4000 \
#     data.filter_overlong_prompts=True \
#     data.truncation='error' \
#     actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_210_ew_grpo_copypaste_v6_ew/step_250_hg \
#     actor_rollout_ref.actor.optim.lr=1e-6 \
#     actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
#     actor_rollout_ref.actor.optim.warmup_style=cosine \
#     actor_rollout_ref.actor.optim.total_training_steps=249 \
#     actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
#     actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
#     actor_rollout_ref.actor.optim.clip_grad=0.5 \
#     actor_rollout_ref.model.use_remove_padding=True \
#     actor_rollout_ref.actor.ppo_mini_batch_size=8 \
#     actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
#     actor_rollout_ref.actor.use_kl_loss=True \
#     actor_rollout_ref.actor.kl_loss_type=low_var_kl \
#     actor_rollout_ref.actor.kl_loss_coef=0.25 \
#     ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
#     actor_rollout_ref.actor.grad_clip=0.5 \
#     actor_rollout_ref.actor.entropy_coeff=0.0004 \
#     ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
#     actor_rollout_ref.model.enable_gradient_checkpointing=True \
#     actor_rollout_ref.actor.fsdp_config.param_offload=True \
#     +actor_rollout_ref.ref.gpu_offload=True \
#     actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
#     actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
#     actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
#     actor_rollout_ref.rollout.name=vllm \
#     actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
#     actor_rollout_ref.rollout.top_p=0.8 \
#     actor_rollout_ref.rollout.top_k=20 \
#     actor_rollout_ref.rollout.n=4 \
#     actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
#     ++actor_rollout_ref.rollout.enable_prefix_caching=true \
#     +actor_rollout_ref.rollout.repetition_penalty=1.01 \
#     actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
#     actor_rollout_ref.ref.fsdp_config.param_offload=True \
#     algorithm.use_kl_in_reward=False \
#     trainer.critic_warmup=0 \
#     trainer.logger='["console","wandb"]' \
#     trainer.project_name='verl_grpo_dna_assemble_3500' \
#     trainer.experiment_name='step_250_ew_ew_grpo_copypaste_v8_tc' \
#     trainer.default_local_dir=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_250_ew_ew_grpo_copypaste_v8_tc \
#     trainer.n_gpus_per_node=4 \
#     trainer.nnodes=1 \
#     trainer.save_freq=10 \
#     trainer.test_freq=10 \
#     trainer.log_val_generations=50 \
#     trainer.total_epochs=1 $@


# Train v7-2A3B from last step of [v8-tc]: step_250_ew_ew_tc_grpo_copypaste_v7_ew 3A0B -> 0A3B -> 1A3B -> 1.5A3B -> 2A3B (equal weight)
export WANDB_PROJECT=verl_grpo_dna_assemble_3500
python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
export WANDB_MODE=offline

python3 -m verl.trainer.main_ppo \
    custom_reward_function.path=/path/demo/script/RL/reward_function_equal_weight.py \
    algorithm.adv_estimator=grpo \
    data.train_files=/path/demo/genegene_copypaste_train_v7.parquet \
    data.val_files=/path/demo/genegene_copypaste_val_v7.parquet \
    data.train_batch_size=8 \
    data.max_prompt_length=40000 \
    data.max_response_length=4000 \
    data.filter_overlong_prompts=True \
    data.truncation='error' \
    actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_250_ew_ew_grpo_copypaste_v8_tc/step_250_hg \
    actor_rollout_ref.actor.optim.lr=1e-6 \
    actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
    actor_rollout_ref.actor.optim.warmup_style=cosine \
    actor_rollout_ref.actor.optim.total_training_steps=249 \
    actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
    actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
    actor_rollout_ref.actor.optim.clip_grad=0.5 \
    actor_rollout_ref.model.use_remove_padding=True \
    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
    actor_rollout_ref.actor.use_kl_loss=True \
    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
    actor_rollout_ref.actor.kl_loss_coef=0.25 \
    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
    actor_rollout_ref.actor.grad_clip=0.5 \
    actor_rollout_ref.actor.entropy_coeff=0.0004 \
    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
    actor_rollout_ref.model.enable_gradient_checkpointing=True \
    actor_rollout_ref.actor.fsdp_config.param_offload=True \
    +actor_rollout_ref.ref.gpu_offload=True \
    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
    actor_rollout_ref.rollout.name=vllm \
    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
    actor_rollout_ref.rollout.top_p=0.8 \
    actor_rollout_ref.rollout.top_k=20 \
    actor_rollout_ref.rollout.n=4 \
    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
    actor_rollout_ref.ref.fsdp_config.param_offload=True \
    algorithm.use_kl_in_reward=False \
    trainer.critic_warmup=0 \
    trainer.logger='["console","wandb"]' \
    trainer.project_name='verl_grpo_dna_assemble_3500' \
    trainer.experiment_name='step_250_ew_ew_tc_grpo_copypaste_v7_ew' \
    trainer.default_local_dir=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_250_ew_ew_tc_grpo_copypaste_v7_ew \
    trainer.n_gpus_per_node=4 \
    trainer.nnodes=1 \
    trainer.save_freq=10 \
    trainer.test_freq=10 \
    trainer.log_val_generations=50 \
    trainer.total_epochs=1 $@

# Train v7-2A3B from last step of [v8-tc]: step_250_ew_ew_tc_grpo_copypaste_v7_br 3A0B -> 0A3B -> 1A3B -> 1.5A3B -> 2A3B (batch random)
export WANDB_PROJECT=verl_grpo_dna_assemble_3500
python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
export WANDB_MODE=offline

python3 -m verl.trainer.main_ppo \
    reward_model.reward_manager=batch \
    custom_reward_function.path=/path/demo/script/RL/reward_function_batch_random.py \
    custom_reward_function.name=compute_score_batch \
    algorithm.adv_estimator=grpo \
    data.train_files=/path/demo/genegene_copypaste_train_v7.parquet \
    data.val_files=/path/demo/genegene_copypaste_val_v7.parquet \
    data.train_batch_size=8 \
    data.max_prompt_length=40000 \
    data.max_response_length=4000 \
    data.filter_overlong_prompts=True \
    data.truncation='error' \
    actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_250_ew_ew_grpo_copypaste_v8_tc/step_250_hg \
    actor_rollout_ref.actor.optim.lr=1e-6 \
    actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
    actor_rollout_ref.actor.optim.warmup_style=cosine \
    actor_rollout_ref.actor.optim.total_training_steps=249 \
    actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
    actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
    actor_rollout_ref.actor.optim.clip_grad=0.5 \
    actor_rollout_ref.model.use_remove_padding=True \
    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
    actor_rollout_ref.actor.use_kl_loss=True \
    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
    actor_rollout_ref.actor.kl_loss_coef=0.25 \
    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
    actor_rollout_ref.actor.grad_clip=0.5 \
    actor_rollout_ref.actor.entropy_coeff=0.0004 \
    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
    actor_rollout_ref.model.enable_gradient_checkpointing=True \
    actor_rollout_ref.actor.fsdp_config.param_offload=True \
    +actor_rollout_ref.ref.gpu_offload=True \
    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
    actor_rollout_ref.rollout.name=vllm \
    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
    actor_rollout_ref.rollout.top_p=0.8 \
    actor_rollout_ref.rollout.top_k=20 \
    actor_rollout_ref.rollout.n=4 \
    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
    actor_rollout_ref.ref.fsdp_config.param_offload=True \
    algorithm.use_kl_in_reward=False \
    trainer.critic_warmup=0 \
    trainer.logger='["console","wandb"]' \
    trainer.project_name='verl_grpo_dna_assemble_3500' \
    trainer.experiment_name='step_250_ew_ew_tc_grpo_copypaste_v7_br' \
    trainer.default_local_dir=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_250_ew_ew_tc_grpo_copypaste_v7_br \
    trainer.n_gpus_per_node=4 \
    trainer.nnodes=1 \
    trainer.save_freq=10 \
    trainer.test_freq=10 \
    trainer.log_val_generations=50 \
    trainer.total_epochs=1 $@

# Train v7-2A3B from last step of [v8-tc]: step_250_ew_ew_tc_grpo_copypaste_v7_tc 3A0B -> 0A3B -> 1A3B -> 1.5A3B -> 2A3B (target curve)
export WANDB_PROJECT=verl_grpo_dna_assemble_3500
python -m wandb login --relogin b89c31f42e528d3c353f06f0f263ca3d8335ab57
export WANDB_MODE=offline

python3 -m verl.trainer.main_ppo \
    reward_model.reward_manager=batch \
    custom_reward_function.path=/path/demo/script/RL/reward_function_target_curve.py \
    custom_reward_function.name=compute_score_batch \
    algorithm.adv_estimator=grpo \
    data.train_files=/path/demo/genegene_copypaste_train_v7.parquet \
    data.val_files=/path/demo/genegene_copypaste_val_v7.parquet \
    data.train_batch_size=8 \
    data.max_prompt_length=40000 \
    data.max_response_length=4000 \
    data.filter_overlong_prompts=True \
    data.truncation='error' \
    actor_rollout_ref.model.path=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_250_ew_ew_grpo_copypaste_v8_tc/step_250_hg \
    actor_rollout_ref.actor.optim.lr=1e-6 \
    actor_rollout_ref.actor.optim._target_=verl.workers.config.FSDPOptimizerConfig \
    actor_rollout_ref.actor.optim.warmup_style=cosine \
    actor_rollout_ref.actor.optim.total_training_steps=249 \
    actor_rollout_ref.actor.optim.min_lr_ratio=5e-7 \
    actor_rollout_ref.actor.optim.lr_warmup_steps=0 \
    actor_rollout_ref.actor.optim.clip_grad=0.5 \
    actor_rollout_ref.model.use_remove_padding=True \
    actor_rollout_ref.actor.ppo_mini_batch_size=8 \
    actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1 \
    actor_rollout_ref.actor.use_kl_loss=True \
    actor_rollout_ref.actor.kl_loss_type=low_var_kl \
    actor_rollout_ref.actor.kl_loss_coef=0.25 \
    ++actor_rollout_ref.actor.policy_loss.ppo_kl_coef=0.25 \
    actor_rollout_ref.actor.grad_clip=0.5 \
    actor_rollout_ref.actor.entropy_coeff=0.0004 \
    ++actor_rollout_ref.rollout.enable_chunked_prefill=true \
    actor_rollout_ref.model.enable_gradient_checkpointing=True \
    actor_rollout_ref.actor.fsdp_config.param_offload=True \
    +actor_rollout_ref.ref.gpu_offload=True \
    actor_rollout_ref.actor.fsdp_config.optimizer_offload=True \
    actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=4 \
    actor_rollout_ref.rollout.tensor_model_parallel_size=2 \
    actor_rollout_ref.rollout.name=vllm \
    actor_rollout_ref.rollout.gpu_memory_utilization=0.95 \
    actor_rollout_ref.rollout.top_p=0.8 \
    actor_rollout_ref.rollout.top_k=20 \
    actor_rollout_ref.rollout.n=4 \
    actor_rollout_ref.rollout.max_num_batched_tokens=49152 \
    ++actor_rollout_ref.rollout.enable_prefix_caching=true \
    +actor_rollout_ref.rollout.repetition_penalty=1.01 \
    actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=4 \
    actor_rollout_ref.ref.fsdp_config.param_offload=True \
    algorithm.use_kl_in_reward=False \
    trainer.critic_warmup=0 \
    trainer.logger='["console","wandb"]' \
    trainer.project_name='verl_grpo_dna_assemble_3500' \
    trainer.experiment_name='step_250_ew_ew_tc_grpo_copypaste_v7_tc' \
    trainer.default_local_dir=/path/demo/checkpoints/verl_grpo_dna_assemble_3500/step_250_ew_ew_tc_grpo_copypaste_v7_tc \
    trainer.n_gpus_per_node=4 \
    trainer.nnodes=1 \
    trainer.save_freq=10 \
    trainer.test_freq=10 \
    trainer.log_val_generations=50 \
    trainer.total_epochs=1 $@